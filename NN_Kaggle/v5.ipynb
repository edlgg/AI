{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# virtualenv -p python3 venv\n",
    "# source venv/bin/activate\n",
    "# pip install pandas numpy scikit-learn tensorflow jupyter ipykernel\n",
    "# python -m ipykernel install --user --name venv --display-name \"My Env\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_raw = pd.read_csv(\"train.csv\",header=0).sample(frac=1) # Eduardo\n",
    "test_raw = pd.read_csv(\"test.csv\",header=0) # Eduardo\n",
    "store_raw = pd.read_csv(\"store.csv\",header=0) # Eduardo\n",
    "#data_train= pd.read_csv(\"/content/drive/My Drive/Kaggle/train.csv\",header=0) #David\n",
    "\n",
    "\n",
    "train_raw.drop(\"Customers\", inplace=True, axis=1) # Drop customers colum because it is not present on test set.\n",
    "test_raw.drop(\"Id\", inplace=True, axis=1) # Not relevant\n",
    "\n",
    "# Add sales column to train to mantain consistency in transformations.\n",
    "test_raw[\"Sales\"] = [0] * len(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class VoidTransformer(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self):\n",
    "    return\n",
    "  def fit(self, X, y=None):\n",
    "    return self\n",
    "  def transform(self, X, y=None):\n",
    "    return X\n",
    "\n",
    "class DateSplitter(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self):\n",
    "    return\n",
    "  def fit(self, X, y=None):\n",
    "    return self\n",
    "  def transform(self, X, y=None):\n",
    "    days = []\n",
    "    for date in X[\"Date\"]: # NOTE: Se podra paralelizar?\n",
    "      year, month, day = date.split(\"-\")\n",
    "      total = int(year) * 365 + int(month) * 30 + int(day)\n",
    "      days.append(total)\n",
    "    return np.c_[days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipeline = ColumnTransformer([\n",
    "                                  (\"nothing1\", VoidTransformer(),  [\"Store\"]),\n",
    "                                  (\"Categorical1\", OneHotEncoder(), [\"DayOfWeek\"]),\n",
    "                                  (\"date\", DateSplitter(), [\"Date\"]),\n",
    "                                  (\"nothing2\", VoidTransformer(), [\"Open\", \"Promo\"]),\n",
    "                                  # (\"Categorical2\", OneHotEncoder(), [\"StateHoliday\"]), # NOTE: Should one hot\n",
    "                                  (\"nothing3\", VoidTransformer(), [\"SchoolHoliday\", \"Sales\"]),\n",
    "\n",
    "])\n",
    "train_prepared = features_pipeline.fit_transform(train_raw)\n",
    "train_prepared = pd.DataFrame(train_prepared)\n",
    "train_prepared.rename(columns = {0:'Store', 12:'Sales', 8:'Days'}, inplace = True)\n",
    "\n",
    "test_prepared = features_pipeline.fit_transform(test_raw)\n",
    "test_prepared = pd.DataFrame(test_prepared)\n",
    "test_prepared.rename(columns = {0:'Store', 12:'Sales', 8:'Days'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_onehot_pipeline = Pipeline([\n",
    "            (\"nan_to_0\", SimpleImputer(strategy=\"constant\")),\n",
    "            (\"one_hot\", OneHotEncoder())                    \n",
    "])\n",
    "\n",
    "store_pipeline = ColumnTransformer([\n",
    "                                  (\"nothing1\", SimpleImputer(strategy='constant', fill_value=1), [\"Store\"]),\n",
    "                                  (\"Categorial1\", nan_onehot_pipeline, [\"StoreType\", \"Assortment\"]),\n",
    "                                  (\"CompetitionDistance\", SimpleImputer(strategy='mean'), [\"CompetitionDistance\"]),\n",
    "                                  (\"CompetitionSinceMonth\", SimpleImputer(strategy='constant'), [\"CompetitionOpenSinceMonth\"]),\n",
    "                                  (\"CompetitionSinceYear\", SimpleImputer(strategy='constant', fill_value=2016), [\"CompetitionOpenSinceYear\"]),\n",
    "                                  (\"nothing2\", VoidTransformer(), [\"Promo2\"]),\n",
    "                                  (\"Promo2SinceWeek\", SimpleImputer(strategy='constant'), [\"Promo2SinceWeek\"]),\n",
    "                                  (\"Promo2SinceYear\", SimpleImputer(strategy='constant', fill_value=2016), [\"Promo2SinceYear\"]),\n",
    "                                  (\"Categorical2\", nan_onehot_pipeline, [\"PromoInterval\"]),\n",
    "])\n",
    "\n",
    "stores_prepared = store_pipeline.fit_transform(store_raw)\n",
    "stores_prepared = pd.DataFrame(stores_prepared)\n",
    "stores_prepared.rename(columns = {0:'Store'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_prepared.merge(stores_prepared, on='Store', sort=False)\n",
    "test = test_prepared.merge(stores_prepared, on='Store', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test[\"Sales\"]\n",
    "test_features = test.drop(\"Sales\", axis=1)\n",
    "train_labels = train[\"Sales\"]\n",
    "train_features = train.drop(\"Sales\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_scaled =  preprocessing.MinMaxScaler().fit_transform(train_features.values)\n",
    "# train_features = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    # return K.sqrt(K.mean(K.square((y_true - y_pred) / K.clip(K.abs(y_true),K.epsilon(),None) ), axis=-1) )\n",
    "    return K.sqrt(K.mean(K.square((y_true - y_pred) / (y_true+1)), axis=-1) )\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "train_features = pd.DataFrame(x_scaled)\n",
    "train_features = np.expand_dims(train_features, axis=-1)\n",
    "input_shape = train_features.shape[1]\n",
    "model = Sequential([\n",
    "              layers.Conv1D(filters=20, kernel_size=3, input_shape=(train_features.shape[1],1)),\n",
    "              layers.Flatten(),\n",
    "              # layers.MaxPool1D(),  \n",
    "              layers.Dense(20, activation='sigmoid'),\n",
    "              layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='mse',\n",
    "              metrics=[rmspe, rmse, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_features, train_labels.values, batch_size=32, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarisar datos\n",
    "# knn imputer\n",
    "# RMSPError\n",
    "# feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[2000:2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y[2000:2010]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}